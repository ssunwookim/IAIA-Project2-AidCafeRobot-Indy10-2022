# 2. Ade Robot Algorithm  

## QR Classifier

### 1) **Package Install**

```bash
# Install QR package
py38
pip install pyzbar # QR code including just text
pip install beautifulsoup4 # QR code including html adress 
```



### 2) **Generate QR Code**

- There are many types of data included in QR codes
- We basically use **text type** QR codes
- Generate QR code: [Link](https://ko.qr-code-generator.com/)

- We choose text type of the 4 QR codes as **Greengrape, Orange, Strawberry, and Peach**



### 3) **Code Install Procedure (Detecting QR Codes)**

```bash
# Choose Simulation or Real Robot
roslaunch indy10_gazebo indy10_moveit_gazebo.launch # Simulation
roslaunch indy10_moveit_config moveit_planning_execution.launch robot_ip:=192.168.0.8 # Real

v4l2-ctl --list-devices # See Camera Index, change to appropriate index of the camera, can skip this step

rosrun indy_driver camera1.py
rosrun indy_driver image_display1.py # QR display, can skip this step

py38 # Activate

rosrun indy_driver QR_classifier.py # QR Detection, Publish drint_info
```



### **4) QR Classifier Algorithm

- Subscribe `camera/image_raw1` from the published Camera 1 image node
- Publish `drink_info` if same QR code is detected over 20 times

- Using **pyzbar** package allows the program to read contents of the QR codes

- If the contents of the QR codes are  including other forms of the data, like HTML addresses, Read the contents in the HTML addresses and find

  (**Greengrape, Orange, Strawberry, and Peach**) keywords in the link

- To read HTML data, use **beautifulsoup4** packages



```python
#!/usr/bin/env python3
# -*- coding:utf-8 -*- 

import rospy
from sensor_msgs.msg import Image   # sensor_msgs 패키지로부터 Image 메시지 타입을 import
from cv_bridge import CvBridge, CvBridgeError      # cv_bridge 라이브러리 : OpenCV 이미지와 ROS 메시지 간의 변환 가능
from pyzbar.pyzbar import decode
import requests
from bs4 import BeautifulSoup
from indy_driver.msg import drink_info

class QRClassifierNode:
    def __init__(self):
        # ROS 초기화
        rospy.init_node("qr_classifier", anonymous=True)

        # ROS 메시지 변환 도구 (OpenCV <-> ROS Image)
        self.bridge = CvBridge()

        # 이미지 구독자 설정
        self.image_sub = rospy.Subscriber("camera/image_raw1", Image, self.process_image)

        # 음료 정보 퍼블리셔 설정
        self.drink_pub = rospy.Publisher("drink_info", drink_info, queue_size=10)

        # QR 코드 안정성 타이머 및 URL
        self.timer_start = None
        self.last_recognized_data = None

        # 연속 인식 카운트 및 임계값 설정
        self.chk_cnt = 0
        self.thresh_cnt = 20  # 연속적으로 20개 QR 코드가 인식될 때만 실행

        # 음료 키워드 리스트
        self.drink_keywords = ["Greengrape", "Orange", "Strawberry", "Peach"]
    def process_image(self, data):
        try:
            # 수신된 Image 메시지를 OpenCV 이미지로 변환
            cv_image = self.bridge.imgmsg_to_cv2(data, "bgr8")

            # 이미지에서 QR 코드 디코딩
            qr_codes = decode(cv_image)
            if qr_codes:
                for qr_code in qr_codes:
                    # QR 코드 데이터 가져오기
                    qr_data = qr_code.data.decode("utf-8")
                    rospy.loginfo("QR Code Detected: %s", qr_data)

                    # 텍스트인 경우 바로 처리
                    self.extract_and_publish_drink_info_from_text(qr_data)

        except CvBridgeError as e:
            rospy.logerr("CvBridge Error: %s", str(e))

    def extract_and_publish_drink_info(self, url):
        try:
            # URL에 GET 요청
            response = requests.get(url)
            if response.status_code == 200:
                # 웹 페이지 내용 파싱
                soup = BeautifulSoup(response.text, "html.parser")
                page_text = " ".join(soup.get_text().split())

                # 음료 키워드 탐색
                for keyword in self.drink_keywords:
                    if keyword in page_text:
                        # ROS 메시지 생성 및 퍼블리시
                        drink_message = drink_info()
                        drink_message.name = keyword
                        self.drink_pub.publish(drink_message)
                        rospy.loginfo("Published Drink: %s", keyword)
                        return

                # 키워드가 없는 경우 로그 경고
                rospy.logwarn("No drink keywords found in the webpage.")
            else:
                rospy.logerr("Failed to fetch URL: HTTP %d", response.status_code)
        except Exception as e:
            rospy.logerr("Error fetching or processing URL: %s", str(e))

    def extract_and_publish_drink_info_from_text(self, text):
        # 텍스트에서 음료 키워드 탐색
        for keyword in self.drink_keywords:
            if keyword in text:
                # 연속적인 인식 여부 체크
                if text == self.last_recognized_data:
                    self.chk_cnt += 1
                else:
                    self.chk_cnt = 1  # 처음 인식된 경우

                # 일정 횟수 이상 연속 인식되었을 때만 퍼블리시
                if self.chk_cnt >= self.thresh_cnt:
                    # ROS 메시지 생성 및 퍼블리시
                    drink_message = drink_info()
                    drink_message.name = keyword
                    self.drink_pub.publish(drink_message)
                    rospy.loginfo("Published Drink: %s", keyword)
                    self.chk_cnt = 0  # 카운트 리셋

                self.last_recognized_data = text  # 마지막 인식된 데이터를 갱신
                return

        # 텍스트에서 키워드가 없는 경우 로그 경고
        rospy.logwarn("No drink keywords found in the text.")

    def run(self):
        rospy.spin()

if __name__ == "__main__":
    try:
        qr_classifier = QRClassifierNode()
        qr_classifier.run()
    except rospy.ROSInterruptException:
        pass

```



### 5) **QR classifier result**

| **Green grape**                                              | **Orange**                                                   |
| ------------------------------------------------------------ | ------------------------------------------------------------ |
| **![Q1.png](https://github.com/ssunwookim/IAIA-Project2-AidCafeRobot-Indy10-2022/blob/main/img/QR_img/Q1.png?raw=true)** | **![Q2.png](https://github.com/ssunwookim/IAIA-Project2-AidCafeRobot-Indy10-2022/blob/main/img/QR_img/Q2.png?raw=true)** |
| **Strawberry**                                               | **Peach**                                                    |
| ![Q3.png](https://github.com/ssunwookim/IAIA-Project2-AidCafeRobot-Indy10-2022/blob/main/img/QR_img/Q3.png?raw=true) | ![Q4.png](https://github.com/ssunwookim/IAIA-Project2-AidCafeRobot-Indy10-2022/blob/main/img/QR_img/Q4.png?raw=true) |



## Bottle Classifer

### 1) Package Install

```bash
# Install opencv package
py38
pip install opencv-python==4.10.0.84
```



### 2) Camera & Image Display

 First, you need to check whether the camera 2 is linked and whether the video at that time is displayed. To do that, make sure that the camera is working by specifying a number that meets the computer's specifications. The code below is the camera linking code and the image linking code.



#### **camera2.py**

```python
#!/usr/bin/env python3
#-*- coding:utf-8 -*-
import rospy
import cv2
from sensor_msgs.msg import Image               # sensor_msg 패키지로부터 Image type을 import함
from cv_bridge import CvBridge, CvBridgeError   # cv_bridge 라이브러리 : OpenCV 이미지와 ROS 메시지 간의 변환 가능

class CameraNode2:

    def __init__(self):
        rospy.init_node('camera_node2', anonymous=True)  # 노드 이름 "camera_node"로 초기화
        self.bridge = CvBridge()                # cv_bridge 객체 생성

        # "camera/image_raw"라는 토픽으로 메시지를 publish할 publisher 객체 생성
        self.image_pub = rospy.Publisher("camera/image_raw2",Image,queue_size=1)    
        
        self.cap = cv2.VideoCapture(2)          # 카메라 연결을 위한 VideoCapture 객체 생성
        self.cap.set(cv2.CAP_PROP_FRAME_WIDTH, 640)   # 프레임 너비 
        self.cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 480) 

    def run(self):
        rate = rospy.Rate(30)                           # 루프 실행 주기 : 30hz
        while not rospy.is_shutdown():                  # ROS가 종료되지 않은 동안
            ret, frame = self.cap.read()                # 카메라로부터 이미지를 읽음
            if ret:                                     # 이미지가 정상적으로 읽혀진 경우
                try:
                    # 읽어들인 이미지를 ROS Image 메시지로 변환하여 토픽으로 publish
                    self.image_pub.publish(self.bridge.cv2_to_imgmsg(frame, "bgr8"))
                
                except CvBridgeError as e:
                    print(e)                            # CvBridge 변환 예외 처리
            rate.sleep()                                # 지정된 루프 실행 주기에 따라 대기

if __name__ == '__main__':
    try:
        camera = CameraNode2()       # CameraNode 객체 생성
        camera.run()                # run 메서드 실행
    except rospy.ROSInterruptException:
        pass
```

​       

#### **Image_display2.py**    

```python
#!/usr/bin/env python3
#-*- coding:utf-8 -*- 

import rospy
from sensor_msgs.msg import Image   # sensor_msgs 패키지로부터 Image 메시지 타입을 import
from cv_bridge import CvBridge      # cv_bridge 라이브러리 : OpenCV 이미지와 ROS 메시지 간의 변환 가능
import cv2                          # OpenCV 라이브러리

class DisplayNode2:

    def __init__(self):
        self.bridge = CvBridge()
        self.image_sub = rospy.Subscriber("camera/image_raw2",Image,self.callback)  # camera/image_raw 토픽에서 Image 메시지 수신

    def callback(self,data):
        try:
            # 수신된 Image 메시지를 OpenCV 이미지로 변환
            cv_image = self.bridge.imgmsg_to_cv2(data, "bgr8")  
        except CvBridgeError as e:
            print(e)

        cv2.imshow("Camera", cv_image)  # 변환된 이미지를 "Camera"라는 이름의 윈도우에 표시
        cv2.waitKey(1)                  # 1ms 동안 키보드 입력 대기

    def run(self):
        rospy.init_node('display_node2', anonymous=True) # 노드 초기화 및 이름 설정
        rospy.spin()                                    # 노드가 종료될 때까지 계속 실행

if __name__ == '__main__':
    try:
        display = DisplayNode2()     # DisplayNode 클래스의 인스턴스 생성
        display.run()               # 노드 실행
    except rospy.ROSInterruptException:
        pass
```



#### Image display result

![1.png](https://github.com/ssunwookim/IAIA-Project2-AidCafeRobot-Indy10-2022/blob/main/img/report_Aderobot/1.png?raw=true)

- If camera2 and display2 are linked well, the video will come out as shown this image.



### 3) Bottle Classifer Algorithm

#### ROI Setting

 If it was confirmed that the camera was linked, each bottle was classified to check the status of each of the four bottles. At this time, the ROI was used to set the appropriate section for each bottle.

```Python
# Define ROIs for 4 bottles 
bottle_rois = [
    (86, 231, 157, 476),   # Bottle 1 ROI
    (219, 229, 303, 478),  # Bottle 2 ROI
    (342, 231, 434, 476),  # Bottle 3 ROI
    (489, 233, 563, 474)   # Bottle 4 ROI
]

```

As shown in the code above, four ROI ranges were set to check the status of each.





#### To calculate the amount of syrup

![image-20241221055951435](C:\Users\ksw86\AppData\Roaming\Typora\typora-user-images\image-20241221055951435.png)

 Next, if you set the range using the ROI, you should recognize how much syrup there is in each ROI. For recognition, in this project, the ratio of pixels was used to represent it. In other words, as shown in Figure 2, the number of pixels recognized by HSV was divided and multiplied by 100 to determine the amount of liquid remaining.

```Python
    def calculate_liquid_level(self, frame, roi, lower_color, upper_color):
        x1, y1, x2, y2 = roi
        roi_frame = frame[y1:y2, x1:x2]

        # Convert ROI to HSV for color segmentation
        hsv = cv2.cvtColor(roi_frame, cv2.COLOR_BGR2HSV)

        # Create a mask for the liquid using the provided HSV range
        mask = cv2.inRange(hsv, lower_color, upper_color)

        # Calculate the percentage of liquid pixels
        total_pixels = mask.size
        liquid_pixels = cv2.countNonZero(mask)
        percentage = (liquid_pixels / total_pixels) * 100

        return percentage
```





#### Distinguish and discriminate between positive states

 If you have determined the amount of liquid from the above, you should distinguish between small amount and insufficient amount. Therefore, first, set each range using Threshold and add a code that allows the color to change the ROI color if the amount is small or insufficient. In this project, we divide it into two Thresholds, one of which is LOW_THRESHOLD, and if the amount of syrup drops below 20%, the ROI content color turns yellow and the other is EMPTY_THRESHOLD, if the amount of syrup drops below 5%, the ROI content color turns red

```Python
      
      # Calculate the current status (0~4)
        status = 0
        for i, roi in enumerate(bottle_rois):
            liquid_percentage = self.calculate_liquid_level(frame, roi, self.hsv_lower[i], self.hsv_upper[i])
            if liquid_percentage < EMPTY_THRESHOLD:
                status = max(status, i + 1)

            # Draw ROI and bottle number
            x1, y1, x2, y2 = roi
            color = (0, 255, 0) if liquid_percentage >= LOW_THRESHOLD else (0, 0, 255)
            cv2.rectangle(frame, (x1, y1), (x2, y2), color, 2)
            cv2.putText(frame, str(i + 1), (x1, y1 - 10),
                        cv2.FONT_HERSHEY_SIMPLEX, 0.7, color, 2, cv2.LINE_AA)

```



#### Interworking with ROS

To link the above code with ROS, we first used indy_driver.msg. At this time, warning.msg was imported and used. After that, I used Subscriber to subscribe to the real-time image from the camera and then processed the image in the callback function. In addition, I set up a publisher to issue a warning message when the liquid height of the bottle exceeds the threshold through the warning message. In other words, if the bottle of the roi is empty in accordance with the roi number described above, the number is received as string and the number is printed out.

```Python
from indy_driver.msg import warning  

        self.image_sub = rospy.Subscriber("camera/image_raw2", Image, self.image_callback)
        self.warning_pub = rospy.Publisher("warning", warning, queue_size=1)  # 메시지 타입을 String으로 변경
```



#### result

![2.png](https://github.com/ssunwookim/IAIA-Project2-AidCafeRobot-Indy10-2022/blob/main/img/report_Aderobot/2.png?raw=true)

 The following results show that if HSV recognizes the color well, Warning Publishing is zero and normal, and if an empty bottle occurs in a particular number, Warning Publishing will occur for that number and will output an error.



## Ade Robot Algorithm

### 1) ROS System Design  

![3.png](https://github.com/ssunwookim/IAIA-Project2-AidCafeRobot-Indy10-2022/blob/main/img/report_Aderobot/3.png?raw=true)

<center> Figure 1. ROS System </center>

### 2) Install Procedure 


```bash
roslaunch indy10_gazebo indy10_moveit_gazebo.launch # Simulation

roslaunch indy10_moveit_config moveit_planning_execution.launch robot_ip:=192.168.0.8 #Real

v4l2-ctl --list-devices # See Camera Index, change to appropriate index of the camera

rosrun indy_driver camera1.py
rosrun indy_driver image_display1.py # QR

rosrun indy_driver camera2.py
rosrun indy_driver image_display2.py # Bottle

py38 # Activate

rosrun indy_driver QR_classifier.py # QR Detection, Publish drint_info
rosrun indy_driver bottle_classifier.py # Bottle Detection, Publish warning

rosrun indy_driver AdeRobott_activation.py # Main Code
```



### 3) Nodes Design

- Camera 1, Camera 2 (camera1.py, camera2.py)
  - This node generate image data from camera sensor
  - Publish `camera/image_raw1`, `camera/image_raw2`
  - Need to check the camera index
- Image display (image_display1.py, image_display2.py)
  - This node get image data from published node, just to check the camera activation
  - Subscribe `camera/image_raw1`, `camera/image_raw2`
- QR Classifier (QR_classifier.py)
  - This node classify QR code of the syrup type by pyzbar package
  - pyzbar package allow the program to detect QR codes as text, and link as so on
  - We choose text type of the 4 QR codes as **Greengrape, Orange, Strawberry, and Peach**, same as published string data
  - Subscribe `camera/image_raw1`
  - Publish `drink_info`
- Bottle Classifier (bottle_classifier.py)
  - This node classify type of the empty state of syrup type by opencv package
  - OpenCV package allow the program to detect empty state as normal or abnormal using **string type of the numbers**
  - **0: Normal. 1: Greengrape empty, 2: Orange empty, 3: Strawberry empty, 4: Peach empty**
  - Subscribe `camera/image_raw2`
  - Publish `warning`
- Drink Robot (test2.py)
  - This node control robot to supply syrup, ice and cider

  - Subscribe `drink_info`, `warning`

  - Print the menu images when normal state

  - If empty state, the robot do not work and print sold out images



### 4) Ade Cafe Robot Execution

#### Ade Cafe Robot Process Flowchart

![14.png](https://github.com/ssunwookim/IAIA-Project2-AidCafeRobot-Indy10-2022/blob/main/img/report_Aderobot/14.png?raw=true)

#### QR Classifier & Bottle Classifer Process

![4.png](https://github.com/ssunwookim/IAIA-Project2-AidCafeRobot-Indy10-2022/blob/main/img/report_Aderobot/4.png?raw=true)

![5.png](https://github.com/ssunwookim/IAIA-Project2-AidCafeRobot-Indy10-2022/blob/main/img/report_Aderobot/5.png?raw=true)

- The two photos above illustrate an experimental process where QR recognition is used to identify the type of ade, and a Bottle classifier measures the amount of syrup. As shown in the first photo, once the Orange order is entered and the syrup is determined to be sufficient, the process moves forward. In the second photo, although the Orange order is input, the Bottle classifier detects that there is no syrup available.
- If all syrup levels are adequate, as in the first photo, a Normal menu is displayed to inform the user. However, if the syrup for the ordered ade runs out, as seen in the second photo, the menu is adjusted to exclude certain items based on the type of syrup, allowing the user to order different menu options.

| Normal                                                       | GreenGrape x                                                 |
| ------------------------------------------------------------ | ------------------------------------------------------------ |
| ![Normal.png](https://github.com/ssunwookim/IAIA-Project2-AidCafeRobot-Indy10-2022/blob/main/img/Menu_img/Normal.png?raw=true) | ![green_grape_change.png](https://github.com/ssunwookim/IAIA-Project2-AidCafeRobot-Indy10-2022/blob/main/img/Menu_img/green_grape_change.png?raw=true) |
| **Orange x**                                                 | **Strawberry x**                                             |
| ![orange_change.png](https://github.com/ssunwookim/IAIA-Project2-AidCafeRobot-Indy10-2022/blob/main/img/Menu_img/orange_change.png?raw=true) | ![strawberry_change.png](https://github.com/ssunwookim/IAIA-Project2-AidCafeRobot-Indy10-2022/blob/main/img/Menu_img/strawberry_change.png?raw=true) |
| **Peach x**                                                  |                                                              |
| ![peach_change.png](https://github.com/ssunwookim/IAIA-Project2-AidCafeRobot-Indy10-2022/blob/main/img/Menu_img/peach_change.png?raw=true) |                                                              |



#### Indy10 Robot Utilization

First, we introduce four ways to control the movement of a robot arm through the Indy10 interface.

-  `go_to_joint_abs(target_joints)`
  - **Purpose** : Move the robot manipulator to the absolute joint position.
  - **How it works** : Get the current joint values and set them to the specified target joint values. Then, issue a move command to the target joint position and stop when the movement is complete. This function checks whether the target position and the actual position are within the specified tolerance and returns a boolean value.

-  `go_to_joint_rel(relative_pos)`:
  - **Purpose** : Move the target robot manipulator to the relative joint position.
  - **How it works** : Set a new target joint position by adding the input relative position values based on the current joint values. Then, issue a move command and verify the position accuracy after completion.


- `go_to_pose_abs(absolute_xyz, absolute_rpy)`
  - **Purpose** : Move the target robot manipulator to the absolute pose (position and rotation).
  - **How it works** : Get the current pose and set a new target pose with the input absolute position and rotation values. After the move command, check the accuracy by checking whether the current pose and the target pose match.

- `go_to_pose_rel(relative_xyz, relative_rpy)`:

  - **Purpose** : Move the robot manipulator to a relative pose.

  - **How it works** : Add relative position and rotation values to the current pose to set a new target pose. After the command is issued and the movement is completed, check whether the target pose and the current pose match.

 In this experiment, the most commonly used functions are `go_to_joint_abs(target_joints)` and `go_to_pose_rel(relative_xyz, relative_rpy)`. The first function allows the robot arm to move to a desired pose intuitively and easily through a tablet interface. The second function is particularly useful for controlling detailed movements from any position, as it manipulates the end effector of the robot arm based on relative x, y, and z coordinates.

![6.png](https://github.com/ssunwookim/IAIA-Project2-AidCafeRobot-Indy10-2022/blob/main/img/report_Aderobot/6.png?raw=true)

- This picture is a tablet screen linked to a robot. You can check the robot's joint positions on the tablet. You can use these joint positions as absolute coordinates to move the robot arm to the desired position.

```python
init_pose_joints = [(0.0/360)*tau, # joint 1
                    (0.0/360)*tau, # joint 2
                    (0.0/360)*tau, # joint 3
                    (0.0/360)*tau, # joint 4
                    (0.0/360)*tau, # joint 5
                    (0.0/360)*tau] # joint 6
								   # tau = 2 * pi
indy10.go_to_joint_abs(init_pose_joints)
```

- For example, if you want to move a robot arm in a pose like the picture above, you can input the angle for each joint in absolute coordinates as in the code above.



#### Indy10 Robot Process

**Code** : `AdeRoboto_activation.py`

```python
import rospy
from std_msgs.msg import String
from move_group_python_interface2 import MoveGroupPythonInterface
from math import tau


import time
from indy_driver.msg import warning, drink_info

# Process of Image
import cv2
import os

def drink_info_callback(msg):
    global drink_info_received
    drink_info_received = msg.name
    rospy.loginfo(f"Received drink_info: {msg.name}")

def warning_callback(msg):
    global warning_received
    warning_received = msg.name
    rospy.loginfo(f"Received warning: {msg.name}")

# Dont Work

def display_image(image_path):
    if os.path.exists(image_path):
        image = cv2.imread(image_path)
        cv2.imshow("Warning Image", image)
        cv2.waitKey(1)
```

- **Imports**

  - `rospy`: This module is essential for Python scripts to interact with ROS.

  - `std_msgs.msg`: It includes standard ROS message types; here, it imports `String` which is used to handle string messages within ROS.

  - `MoveGroupPythonInterface`: Presumably a custom class imported from a local module (`move_group_python_interface2`) that handles robot arm movement functions.

  - `math.tau`: Provides the mathematical constant τ (tau), which is approximately equal to 6.283185307179586 (2π).

  - `time`: Standard Python module for handling operations related to time.

  - `indy_driver.msg`: Custom ROS message types for a specific robot, likely named "Indy". This imports `warning` and `drink_info` message types.

  - `cv2`: OpenCV library for handling image operations.

  - `os`: Standard library to interact with the operating system.

- **Callback Functions**:

  - `drink_info_callback(msg)`: A callback function designed to handle `drink_info` messages. It sets a global variable `drink_info_received` with the name of the drink received in the message and logs this information.

  - `warning_callback(msg)`: Similar to the `drink_info_callback`, this function deals with `warning` messages, updating a global variable `warning_received` and logging the received warning name.

- **Display Image Function**:
  - `display_image(image_path)`: This function attempts to display an image located at `image_path`. It first checks if the file exists at the specified path using `os.path.exists(image_path)`. If the file is present, it reads the image using `cv2.imread(image_path)`, displays it in a window titled "Warning Image" with `cv2.imshow("Warning Image", image)`, and uses `cv2.waitKey(1)` to keep the window open. This ensures the image is displayed without immediately closing the window, making it possible for users to view warnings or other important information visually.

```python
indy10.move_to_standby()

rel_xyz = [-0.16, -0.20, 0.16]
rel_rpy = [0.0, 0.0, 0.0]
indy10.go_to_pose_rel(rel_xyz, rel_rpy)
                    
indy10.gripper.grip_on()

init_pose_joints = [(77.00/360)*tau, (13.72/360)*tau, (100.16/360)*tau, (-94.92/360)*tau, (74.55/360)*tau, (115.63/360)*tau]          # tau = 2 * pi
indy10.go_to_joint_abs(init_pose_joints)

# 컵 위치로 이동
init_pose_joints = [(45.04/360)*tau, (36.04/360)*tau, (71.38/360)*tau, (-103.53/360)*tau, (46.83/360)*tau, (113.89/360)*tau]          # tau = 2 * pi
indy10.go_to_joint_abs(init_pose_joints)

indy10.gripper.grip_width(110)


rel_xyz = [0.0, -0.35, 0.25]
rel_rpy = [0.0, 0.0, 0.0]
indy10.go_to_pose_rel(rel_xyz, rel_rpy)

init_pose_joints = [(26.31/360)*tau, (-21.96/360)*tau, (106.63/360)*tau, (-90.49/360)*tau, (113.82/360)*tau, (87.36/360)*tau]          # tau = 2 * pi
indy10.go_to_joint_abs(init_pose_joints)

init_pose_joints = [(20.40/360)*tau, (6.30/360)*tau, (127.09/360)*tau, (-76.32/360)*tau, (101.79/360)*tau, (137.31/360)*tau]          # tau = 2 * pi
indy10.go_to_joint_abs(init_pose_joints)
```

-  The following code describes the process of gripping a cup holder and moving it to the syrup dispenser location. Such tasks can be effectively executed by appropriately combining the robot arm's movements using joint absolute coordinates, pose relative coordinates, and gripper actions. For additional details on the rest of the process, please refer to the linked `AdeRobot_activation.py` code.

```python
if warning_received == "0" and drink_info_received == "Peach":
                        # 분기 1

                        # 첫번째 시럽 위치로 이동
                        init_pose_joints = [(-11.01/360)*tau, 
                                            (-8.62/360)*tau, 
                                            (142.90/360)*tau, 
                                            (-94.37/360)*tau, 
                                            (78.57/360)*tau, 
                                            (135.54/360)*tau]          # tau = 2 * pi
                        indy10.go_to_joint_abs(init_pose_joints)
```

-  The code involves a process where syrup is dispensed based on the type of ade and the quantity of syrup detected via two cameras scanning QR codes. Information from `QR_classifier.py` and `bottle_classifier.py` dictates the flow of the process. Conditional statements such as if-else or switch are used to alter the procedure according to the syrup type. Additionally, to reduce the amount of code and enhance efficiency, the positions of various joints in the syrup dispensing section could be stored and accessed using arrays. This method allows for more streamlined and effective management of the robotic operations.



## **Results Analysis**

- The experimental results through the above processes are as follows.

![5.png](https://github.com/ssunwookim/IAIA-Project2-AidCafeRobot-Indy10-2022/blob/main/img/report_Aderobot/5.png?raw=true)

![orange_change.png](https://github.com/ssunwookim/IAIA-Project2-AidCafeRobot-Indy10-2022/blob/main/img/Menu_img/orange_change.png?raw=true)

- In the experiment, if the QR code is recognized without enough orange, the menu is displayed as follows and other menus are recommended to the user.

- If you then select other recommended menus, the following actions will be performed:

  - **1. Add syrup** : The robotic arm places the cup in the syrup location and presses the syrup container to supply syrup.

  - **2. Ice dispenser**: A robotic arm places a cup under an ice dispenser and turns the dispenser to supply ice.

  - **3. Soda dispenser**: When the robotic arm places the cup in front of the soda dispenser, the dispenser dispenses a certain amount of soda after 5 seconds.

  - **4. Ade provide**: The robotic arm delivers the completed ade to a designated location so that the user can drink it.

| 1. Add syrup                                                 | 2. Ice dispenser                                             |
| ------------------------------------------------------------ | ------------------------------------------------------------ |
| ![10.png](https://github.com/ssunwookim/IAIA-Project2-AidCafeRobot-Indy10-2022/blob/main/img/report_Aderobot/10.png?raw=true) | ![11.png](https://github.com/ssunwookim/IAIA-Project2-AidCafeRobot-Indy10-2022/blob/main/img/report_Aderobot/11.png?raw=true) |
| **3. Soda dispenser**                                        | **4. Ade provide**                                           |
| ![12.png](https://github.com/ssunwookim/IAIA-Project2-AidCafeRobot-Indy10-2022/blob/main/img/report_Aderobot/12.png?raw=true) | ![13.png](https://github.com/ssunwookim/IAIA-Project2-AidCafeRobot-Indy10-2022/blob/main/img/report_Aderobot/13.png?raw=true) |

-  The goal of this experiment was to have the robot automatically create an ade that matches the menu when the menu is recognized through QR and provide it within 2 minutes, and to have the robot automatically replace the syrup by estimating the syrup height with a camera.
-  According to the goal, QR recognition, syrup height estimation through the camera, and automatic ade creation by the robot were all successfully accomplished. As shown in the photo above, you can see that each process is operating accurately. You can check the detailed operation status through the video link below.
-  However, the process of replacing the insufficient syrup according to the targeted syrup height estimation was not performed. I tried to replace the syrup container using a robot arm by manually operating it, but the syrup container was made of glass, so it was very unstable to move it with the robot arm, and the syrup container was not a suitable shape for the robot arm to hold, so in this case, if there was not enough syrup in the syrup container, I ran a roundabout way to exclude the menu from the menu. When this method was implemented, you can see that the menu was normally excluded and shown to the user as shown above.

## Discussion

- The goal of this study was to create a system that automatically produces drinks within two minutes using an aid café robot. We successfully automated the entire drink-making process and achieved the goal of providing drinks of consistent quality with uniform quantities.
- However, a significant drawback was identified as it took approximately 6 to 10 minutes to make a single drink, which is considerably longer than targeted. The reasons for these results are analyzed as follows:
  - The robot takes about 5 seconds to complete an action and move to the next one. However, since the robot has to perform tasks such as pressing the syrup containers and operating the ice dispenser directly, it had to handle many tasks simultaneously. Additionally, the system tended to slow down with prolonged operation of the robot, sometimes taking more than 15 seconds to transition to the next action. These issues significantly impacted the time taken to produce the aids.
  - A potential solution is to automate parts like syrup dispensing and ice dispensing with an embedded system. While not all components were implemented within the timeframe of this experiment, setting up such embedded systems to minimize robot movements could potentially reduce the time by more than 3 minutes.

- During this research, there was a process where the ice dispenser provided a fixed amount of ice efficiently. However, occasionally, the robot arm failed to grasp the handle of the ice dispenser, or the ice would melt quickly and drip down if not insulated properly.
  - To solve these issues, automating the turning of the dispenser with motors and enhancing the insulation of the ice storage could be effective. Another approach might involve using ultrasonic sensors to rapidly produce ice in real-time when approached within a certain distance, significantly reducing the likelihood of environmental mess or loss due to melting.

-  As mentioned in the results above, the task of replacing the syrup container was not properly implemented due to stability reasons. In this case, a stable product such as plastic was used for the syrup container, and since the shape is round and difficult for the gripper to hold, a method is to make the shape of the container square so that the gripper can hold it stably. However, since it is inefficient for the robot to perform this process directly, it is efficient to manufacture the syrup process in the form of a dispenser that places a large amount of syrup on top and automatically supplies the syrup.
-  In this experiment, the QR recognition part and the syrup container height estimation part were performed through image processing. Therefore, there are parts where recent AI technology has not been used densely. When thinking about additional tasks that can be performed using AI during the Ade production process, we expect that the following functions can be performed.
  -  During the experiment, if the robot arm did not properly hold the cup, the cup would spill, or the ice would melt and the surrounding environment would become dirty. In this case, the experimenters had to stop the robot and clean up the surrounding environment. However, if this robot were actually operated, the experimenters would not be able to do the following actions every time. Therefore, it is expected that the surrounding environment can be configured to be easy for the robot to clean, and if an accident such as a spilled cup occurs, a function can be added so that the camera automatically recognizes this and allows the robot to clean up the surrounding environment.

## Troubleshooting

![7.png](https://github.com/ssunwookim/IAIA-Project2-AidCafeRobot-Indy10-2022/blob/main/img/report_Aderobot/7.png?raw=true)

-  Operating the Indy10 robot, you may encounter situations where it fails to perform designated tasks and exhibits erratic movements, leading to system divergence. This issue often arises during repeated operations of the robot. The problem persists even when delays are introduced between actions. One effective method is to manually input commands to guide the robot through each step of the operation. However, this approach does not fully resolve the divergence, and thus cannot be considered a complete solution. Therefore, if the robot has been operating for a set duration, a system reset and restart are necessary. Additionally, to prevent accidents caused by system divergence, it is crucial to always conduct experiments near an emergency stop button.











